{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final.csv')\n",
    "data = data.drop('Unnamed: 0', axis=1)\n",
    "#data['review_rate'] = data['review_rate'].fillna(' ')\n",
    "#data = data.fillna(data.mean())\n",
    "data = data.drop_duplicates(subset=['review_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50    4012\n",
       "40    2234\n",
       "30     514\n",
       "20     144\n",
       "10      88\n",
       "Name: review_rate, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review_rate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DATA_BINARIZADOR_RESULTADOS(data):\n",
    "    RESULTADO_BINARIO = []\n",
    "\n",
    "    for item in data['review_rate']:\n",
    "        if item < 40:\n",
    "            RESULTADO_BINARIO.append(0)\n",
    "        elif item >= 40:\n",
    "            RESULTADO_BINARIO.append(1)\n",
    "        else:\n",
    "            print(\"Deu feijoada aqui hein\")\n",
    "\n",
    "    data['RESULTADO_BINARIO'] = RESULTADO_BINARIO\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rate</th>\n",
       "      <th>review_body</th>\n",
       "      <th>RESULTADO_BINARIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Pois bem...as fotos dos pratos, bebidas e doce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Espero que utilizem essa avaliação para rever ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>Fomos comer a sobremesa as 20h40, sentamos, pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Pedimos o cardápio e ao chamar o atendente ped...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Fui com algumas amigas em uma segunda-feira, d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_rate                                        review_body  \\\n",
       "0           10  Pois bem...as fotos dos pratos, bebidas e doce...   \n",
       "1           30  Espero que utilizem essa avaliação para rever ...   \n",
       "2           20  Fomos comer a sobremesa as 20h40, sentamos, pe...   \n",
       "3           10  Pedimos o cardápio e ao chamar o atendente ped...   \n",
       "4           50  Fui com algumas amigas em uma segunda-feira, d...   \n",
       "\n",
       "   RESULTADO_BINARIO  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  1  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DATA_BINARIZADOR_RESULTADOS(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    #remove pontuacao, palavras com numeros, deixa o texto em caixa baixa e remove o texto entre colchetes\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = unidecode(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear = lambda x: clear_text(x)\n",
    "data_clean = pd.DataFrame(data.review_body.apply(clear))\n",
    "#data_clean['review_rate'] = data['review_rate'].values\n",
    "data_clean['RESULTADO_BINARIO'] = data['RESULTADO_BINARIO'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_clean[['review_body']], data_clean['RESULTADO_BINARIO'], test_size=0.20, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vector = TfidfVectorizer()\n",
    "t_vector.fit(data_clean['review_body'])\n",
    "train_X = t_vector.transform(X_train['review_body'])\n",
    "test_X = t_vector.transform(X_test['review_body'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar(model, model_name, y, pred):\n",
    "    print(\"Os escores do \", model_name,\" são:\")\n",
    "    print(' acc = ', accuracy_score(y, pred), (\"\\n\"),\n",
    "      'prec = ', precision_score(y, pred), (\"\\n\"),\n",
    "      'recall = ', recall_score(y, pred), (\"\\n\"),\n",
    "      'f1 = ', f1_score(y, pred))\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(' auc = ', roc_auc)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Modelos</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Regressão Logística </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Treino</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc =  0.9195422849991061 \n",
      " prec =  0.9180931345481318 \n",
      " recall =  0.9989985980372521 \n",
      " f1 =  0.9568386725493957\n",
      " auc =  0.6286659656852926\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "log.fit(train_X, y_train)\n",
    "log_pred = log.predict(train_X)\n",
    "\n",
    "\n",
    "print(' acc = ', accuracy_score(y_train, log_pred), (\"\\n\"),\n",
    "      'prec = ', precision_score(y_train, log_pred), (\"\\n\"),\n",
    "      'recall = ', recall_score(y_train, log_pred), (\"\\n\"),\n",
    "      'f1 = ', f1_score(y_train, log_pred))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, log_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(' auc = ', roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Teste</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc =  0.9056468906361687 \n",
      " prec =  0.9082301529497451 \n",
      " recall =  0.9952114924181963 \n",
      " f1 =  0.9497334348819497\n",
      " auc =  0.5660988968940297\n"
     ]
    }
   ],
   "source": [
    "log_pred_test = log.predict(test_X)\n",
    "\n",
    "print(' acc = ', accuracy_score(y_test, log_pred_test), (\"\\n\"),\n",
    "      'prec = ', precision_score(y_test, log_pred_test), (\"\\n\"),\n",
    "      'recall = ', recall_score(y_test, log_pred_test), (\"\\n\"),\n",
    "      'f1 = ', f1_score(y_test, log_pred_test))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, log_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(' auc = ', roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Random Forest otimizando default</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features=2,\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "def random_grid(x, labels):\n",
    "    param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2,4,6,8]}, \n",
    "    {'bootstrap': [False], 'n_estimators': [3,10], 'max_features': [2, 3, 4]},\n",
    "    ]   \n",
    "    grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "    grid_search.fit(x, labels)\n",
    "    print(grid_search.best_estimator_)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "model = random_grid(train_X, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Treino</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc =  1.0 \n",
      " prec =  1.0 \n",
      " recall =  1.0 \n",
      " f1 =  1.0\n",
      " auc =  1.0\n"
     ]
    }
   ],
   "source": [
    "rf_pred = model.predict(train_X)\n",
    "print(' acc = ', accuracy_score(y_train, rf_pred), (\"\\n\"),\n",
    "      'prec = ', precision_score(y_train, rf_pred), (\"\\n\"),\n",
    "      'recall = ', recall_score(y_train, rf_pred), (\"\\n\"),\n",
    "      'f1 = ', f1_score(y_train, rf_pred))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, rf_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(' auc = ', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Teste</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc =  0.89707 \n",
      " prec =  0.89921 \n",
      " recall =  0.99681 \n",
      " f1 =  0.9455\n",
      " auc =  0.51895\n"
     ]
    }
   ],
   "source": [
    "rf_pred_test = model.predict(test_X)\n",
    "print(' acc = ', round(accuracy_score(y_test, rf_pred_test), 5), (\"\\n\"),\n",
    "      'prec = ', round(precision_score(y_test, rf_pred_test), 5), (\"\\n\"),\n",
    "      'recall = ', round(recall_score(y_test, rf_pred_test), 5), (\"\\n\"),\n",
    "      'f1 = ', round(f1_score(y_test, rf_pred_test), 5))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, rf_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(' auc = ', round(roc_auc, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Random Forest: grid seach otimizando acurácia</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features=8,\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "def random_grid(x, labels):\n",
    "    param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2,4,6,8]}, \n",
    "    {'bootstrap': [False], 'n_estimators': [3,10], 'max_features': [2, 3, 4]},\n",
    "    ]   \n",
    "    grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(x, labels)\n",
    "    print(grid_search.best_estimator_)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "model = random_grid(train_X, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Treino</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc =  0.9953513320221705 \n",
      " prec =  0.9948196851962542 \n",
      " recall =  1.0 \n",
      " f1 =  0.9974031162604875\n",
      " auc =  0.9783333333333333\n"
     ]
    }
   ],
   "source": [
    "rf_pred = model.predict(train_X)\n",
    "print(' acc = ', accuracy_score(y_train, rf_pred), (\"\\n\"),\n",
    "      'prec = ', precision_score(y_train, rf_pred), (\"\\n\"),\n",
    "      'recall = ', recall_score(y_train, rf_pred), (\"\\n\"),\n",
    "      'f1 = ', f1_score(y_train, rf_pred))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, rf_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(' auc = ', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Teste</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc =  0.8935 \n",
      " prec =  0.89598 \n",
      " recall =  0.99681 \n",
      " f1 =  0.94371\n",
      " auc =  0.50183\n"
     ]
    }
   ],
   "source": [
    "rf_pred_test = model.predict(test_X)\n",
    "print(' acc = ', round(accuracy_score(y_test, rf_pred_test), 5), (\"\\n\"),\n",
    "      'prec = ', round(precision_score(y_test, rf_pred_test), 5), (\"\\n\"),\n",
    "      'recall = ', round(recall_score(y_test, rf_pred_test), 5), (\"\\n\"),\n",
    "      'f1 = ', round(f1_score(y_test, rf_pred_test), 5))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, rf_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(' auc = ', round(roc_auc, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Random Forest otimizando AUC </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features=4,\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=30,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "def random_grid(x, labels):\n",
    "    param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2,4,6,8]}, \n",
    "    {'bootstrap': [False], 'n_estimators': [3,10], 'max_features': [2, 3, 4]},\n",
    "    ]   \n",
    "    grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='roc_auc')\n",
    "    grid_search.fit(x, labels)\n",
    "    print(grid_search.best_estimator_)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "model = random_grid(train_X, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Treino</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc =  0.9992848203111032 \n",
      " prec =  0.9991995197118271 \n",
      " recall =  1.0 \n",
      " f1 =  0.9995995995995995\n",
      " auc =  0.9966666666666666\n"
     ]
    }
   ],
   "source": [
    "rf_pred = model.predict(train_X)\n",
    "print(' acc = ', accuracy_score(y_train, rf_pred), (\"\\n\"),\n",
    "      'prec = ', precision_score(y_train, rf_pred), (\"\\n\"),\n",
    "      'recall = ', recall_score(y_train, rf_pred), (\"\\n\"),\n",
    "      'f1 = ', f1_score(y_train, rf_pred))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, rf_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(' auc = ', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Teste</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc =  0.89564 \n",
      " prec =  0.89564 \n",
      " recall =  1.0 \n",
      " f1 =  0.94495\n",
      " auc =  0.5\n"
     ]
    }
   ],
   "source": [
    "rf_pred_test = model.predict(test_X)\n",
    "print(' acc = ', round(accuracy_score(y_test, rf_pred_test), 5), (\"\\n\"),\n",
    "      'prec = ', round(precision_score(y_test, rf_pred_test), 5), (\"\\n\"),\n",
    "      'recall = ', round(recall_score(y_test, rf_pred_test), 5), (\"\\n\"),\n",
    "      'f1 = ', round(f1_score(y_test, rf_pred_test), 5))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, rf_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(' auc = ', round(roc_auc, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SVM otimizando default</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=1, gamma='scale', kernel='sigmoid',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "def svm_grid(x, labels):\n",
    "    param_grid = [\n",
    "    {'kernel': ['rbf', 'sigmoid'],\n",
    "        'C': [0.1, 1.0, 10.0, 100.0],\n",
    "        'degree': [1]}\n",
    "    ]   \n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "    grid_search.fit(x, labels)\n",
    "    print(grid_search.best_estimator_)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "model_svc = svm_grid(train_X, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Treino</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc =  0.99928 \n",
      " prec =  0.9992 \n",
      " recall =  1.0 \n",
      " f1 =  0.9996\n",
      " auc =  0.99667\n"
     ]
    }
   ],
   "source": [
    "svm_pred = model.predict(train_X)\n",
    "print(' acc = ', round(accuracy_score(y_train, svm_pred), 5), (\"\\n\"),\n",
    "      'prec = ', round(precision_score(y_train, svm_pred), 5), (\"\\n\"),\n",
    "      'recall = ', round(recall_score(y_train, svm_pred), 5), (\"\\n\"),\n",
    "      'f1 = ', round(f1_score(y_train, svm_pred), 5))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, svm_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(' auc = ', round(roc_auc, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Teste</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc =  0.89564 \n",
      " prec =  0.89564 \n",
      " recall =  1.0 \n",
      " f1 =  0.94495\n",
      " auc =  0.5\n"
     ]
    }
   ],
   "source": [
    "svm_pred_test = model.predict(test_X)\n",
    "print(' acc = ', round(accuracy_score(y_test, svm_pred_test), 5), (\"\\n\"),\n",
    "      'prec = ', round(precision_score(y_test, svm_pred_test), 5), (\"\\n\"),\n",
    "      'recall = ', round(recall_score(y_test, svm_pred_test), 5), (\"\\n\"),\n",
    "      'f1 = ', round(f1_score(y_test, svm_pred_test), 5))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, svm_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(' auc = ', round(roc_auc, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SVM otimizando acurácia</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=1, gamma='scale', kernel='sigmoid',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "def svm_grid(x, labels):\n",
    "    param_grid = [\n",
    "    {'kernel': ['rbf', 'sigmoid'],\n",
    "        'C': [0.1, 1.0, 10.0, 100.0],\n",
    "        'degree': [1]}\n",
    "    ]   \n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(x, labels)\n",
    "    print(grid_search.best_estimator_)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "model_svc = svm_grid(train_X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose'])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC().get_params().keys() #os parametros que dá pra alterar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Treino</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc =  0.99928 \n",
      " prec =  0.9992 \n",
      " recall =  1.0 \n",
      " f1 =  0.9996\n",
      " auc =  0.99667\n"
     ]
    }
   ],
   "source": [
    "svm_pred = model.predict(train_X)\n",
    "print(' acc = ', round(accuracy_score(y_train, svm_pred), 5), (\"\\n\"),\n",
    "      'prec = ', round(precision_score(y_train, svm_pred), 5), (\"\\n\"),\n",
    "      'recall = ', round(recall_score(y_train, svm_pred), 5), (\"\\n\"),\n",
    "      'f1 = ', round(f1_score(y_train, svm_pred), 5))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, svm_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(' auc = ', round(roc_auc, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Teste</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc =  0.89564 \n",
      " prec =  0.89564 \n",
      " recall =  1.0 \n",
      " f1 =  0.94495\n",
      " auc =  0.5\n"
     ]
    }
   ],
   "source": [
    "svm_pred_test = model.predict(test_X)\n",
    "print(' acc = ', round(accuracy_score(y_test, svm_pred_test), 5), (\"\\n\"),\n",
    "      'prec = ', round(precision_score(y_test, svm_pred_test), 5), (\"\\n\"),\n",
    "      'recall = ', round(recall_score(y_test, svm_pred_test), 5), (\"\\n\"),\n",
    "      'f1 = ', round(f1_score(y_test, svm_pred_test), 5))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, svm_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(' auc = ', round(roc_auc, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refazendo os grid search, optando por otimizar a auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SVM otimizando AUC</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=1, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "def svm_grid(x, labels):\n",
    "    param_grid = [\n",
    "    {'kernel': ['rbf', 'sigmoid'],\n",
    "        'C': [0.1, 1.0, 10.0, 100.0],\n",
    "        'degree': [1]}\n",
    "    ]   \n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='roc_auc')\n",
    "    grid_search.fit(x, labels)\n",
    "    print(grid_search.best_estimator_)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "model_svc = svm_grid(train_X, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Treino</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc =  0.99928 \n",
      " prec =  0.9992 \n",
      " recall =  1.0 \n",
      " f1 =  0.9996\n",
      " auc =  0.99667\n"
     ]
    }
   ],
   "source": [
    "svm_pred = model.predict(train_X)\n",
    "print(' acc = ', round(accuracy_score(y_train, svm_pred), 5), (\"\\n\"),\n",
    "      'prec = ', round(precision_score(y_train, svm_pred), 5), (\"\\n\"),\n",
    "      'recall = ', round(recall_score(y_train, svm_pred), 5), (\"\\n\"),\n",
    "      'f1 = ', round(f1_score(y_train, svm_pred), 5))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, svm_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(' auc = ', round(roc_auc, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Teste</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc =  0.89564 \n",
      " prec =  0.89564 \n",
      " recall =  1.0 \n",
      " f1 =  0.94495\n",
      " auc =  0.5\n"
     ]
    }
   ],
   "source": [
    "svm_pred_test = model.predict(test_X)\n",
    "print(' acc = ', round(accuracy_score(y_test, svm_pred_test), 5), (\"\\n\"),\n",
    "      'prec = ', round(precision_score(y_test, svm_pred_test), 5), (\"\\n\"),\n",
    "      'recall = ', round(recall_score(y_test, svm_pred_test), 5), (\"\\n\"),\n",
    "      'f1 = ', round(f1_score(y_test, svm_pred_test), 5))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, svm_pred_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(' auc = ', round(roc_auc, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
