{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANTON_WITH_BERT_AGORA_VAI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj_j2zmTyzrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/prestonlimlianjie/bert-sentiment-analysis-straits-times/blob/master/BERT_sentiment_analysis.ipynb\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH4ZLYNazX3T",
        "colab_type": "code",
        "outputId": "0af69876-a5ba-4e39-e577-11fc2235a809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        }
      },
      "source": [
        "!{sys.executable} -m pip install torch transformers pandas scikit-learn"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 28.8MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 14.9MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 53.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.40)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.40)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=93325e00eb7ae0edc95ab351c3bf07bb3561aa5848daae2d43910dd74fd52db5\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8TDTy2yzNzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define utils functions\n",
        "\n",
        "def pad_sents(sents, pad_token):\n",
        "    \"\"\" Pad list of sentences according to the longest sentence in the batch.\n",
        "    @param sents (list[list[int]]): list of sentences, where each sentence\n",
        "                                    is represented as a list of words\n",
        "    @param pad_token (int): padding token\n",
        "    @returns sents_padded (list[list[int]]): list of sentences where sentences shorter\n",
        "        than the max length sentence are padded out with the pad_token, such that\n",
        "        each sentences in the batch now has equal length.\n",
        "        Output shape: (batch_size, max_sentence_length)\n",
        "    \"\"\"\n",
        "    sents_padded = []\n",
        "\n",
        "    max_len = max(len(s) for s in sents)\n",
        "    batch_size = len(sents)\n",
        "\n",
        "    for s in sents:\n",
        "        padded = [pad_token] * max_len\n",
        "        padded[:len(s)] = s\n",
        "        sents_padded.append(padded)\n",
        "\n",
        "    return sents_padded\n",
        "\n",
        "def sents_to_tensor(tokenizer, sents, device):\n",
        "    \"\"\"\n",
        "    :param tokenizer: BertTokenizer\n",
        "    :param sents: list[str], list of sentences (NOTE: untokenized, continuous sentences), reversely sorted\n",
        "    :param device: torch.device\n",
        "    :return: sents_tensor: torch.Tensor, shape(batch_size, max_sent_length), reversely sorted\n",
        "    :return: masks_tensor: torch.Tensor, shape(batch_size, max_sent_length), reversely sorted\n",
        "    :return: sents_lengths: torch.Tensor, shape(batch_size), reversely sorted\n",
        "    \"\"\"\n",
        "    tokens_list = [tokenizer.tokenize(sent) for sent in sents]\n",
        "    sents_lengths = [len(tokens) for tokens in tokens_list]\n",
        "    # tokens_sents_zip = zip(tokens_list, sents_lengths)\n",
        "    # tokens_sents_zip = sorted(tokens_sents_zip, key=lambda x: x[1], reverse=True)\n",
        "    # tokens_list, sents_lengths = zip(*tokens_sents_zip)\n",
        "    tokens_list_padded = pad_sents(tokens_list, '[PAD]')\n",
        "    sents_lengths = torch.tensor(sents_lengths, device=device)\n",
        "\n",
        "    masks = []\n",
        "    for tokens in tokens_list_padded:\n",
        "        mask = [0 if token=='[PAD]' else 1 for token in tokens]\n",
        "        masks.append(mask)\n",
        "    masks_tensor = torch.tensor(masks, dtype=torch.long, device=device)\n",
        "    tokens_id_list = [tokenizer.convert_tokens_to_ids(tokens) for tokens in tokens_list_padded]\n",
        "    sents_tensor = torch.tensor(tokens_id_list, dtype=torch.long, device=device)\n",
        "\n",
        "    return sents_tensor, masks_tensor, sents_lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hp8neVFzQhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMQnmURGzSwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentClassifierModel(nn.Module):\n",
        "\n",
        "    def __init__(self, bert_config, device, n_class):\n",
        "        \"\"\"\n",
        "        :param bert_config: str, BERT configuration description\n",
        "        :param device: torch.device\n",
        "        :param n_class: int\n",
        "        \"\"\"\n",
        "\n",
        "        super(SentimentClassifierModel, self).__init__()\n",
        "\n",
        "        self.n_class = n_class\n",
        "        self.bert_config = bert_config\n",
        "        self.bert = BertForSequenceClassification.from_pretrained(self.bert_config, num_labels=self.n_class)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(self.bert_config)\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, sents):\n",
        "        \"\"\"\n",
        "        :param sents: list[str], list of sentences (NOTE: untokenized, continuous sentences)\n",
        "        :return: pre_softmax, torch.tensor of shape (batch_size, n_class)\n",
        "        \"\"\"\n",
        "\n",
        "        sents_tensor, masks_tensor, sents_lengths = sents_to_tensor(self.tokenizer, sents, self.device)\n",
        "        pre_softmax = self.bert(input_ids=sents_tensor, attention_mask=masks_tensor)\n",
        "\n",
        "        return pre_softmax\n",
        "\n",
        "    @staticmethod\n",
        "    def load(model_path: str, device):\n",
        "        \"\"\" Load the model from a file.\n",
        "        @param model_path (str): path to model\n",
        "        @return model (nn.Module): model with saved parameters\n",
        "        \"\"\"\n",
        "        params = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
        "        args = params['args']\n",
        "        model = SentimentClassifierModel(device=device, **args)\n",
        "        model.load_state_dict(params['state_dict'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def save(self, path: str):\n",
        "        \"\"\" Save the model to a file.\n",
        "        @param path (str): path to the model\n",
        "        \"\"\"\n",
        "        print('save model parameters to [%s]' % path, file=sys.stderr)\n",
        "\n",
        "        params = {\n",
        "            'args': dict(bert_config=self.bert_config, n_class=self.n_class),\n",
        "            'state_dict': self.state_dict()\n",
        "        }\n",
        "\n",
        "        torch.save(params, path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMsi-vpvzt9O",
        "colab_type": "code",
        "outputId": "46517052-5f33-4314-e04a-3824a3070ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "import pandas\n",
        "\n",
        "pwd = '/content/drive'\n",
        "\n",
        "\n",
        "df= pandas.read_csv(\"/content/drive/My Drive/BERT/Tweets.csv\", index_col=0, usecols=['tweet_id','airline_sentiment', 'text'])\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tweet_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>570306133677760513</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570301130888122368</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570301083672813571</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570301031407624196</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570300817074462722</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   airline_sentiment                                               text\n",
              "tweet_id                                                                               \n",
              "570306133677760513           neutral                @VirginAmerica What @dhepburn said.\n",
              "570301130888122368          positive  @VirginAmerica plus you've added commercials t...\n",
              "570301083672813571           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
              "570301031407624196          negative  @VirginAmerica it's really aggressive to blast...\n",
              "570300817074462722          negative  @VirginAmerica and it's a really big bad thing..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o12sHFpGz45N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove URL, RT, mention(@)\n",
        "\n",
        "df.text = df.text.str.replace(r'http(\\S)+', r'')\n",
        "df.text = df.text.str.replace(r'http ...', r'')\n",
        "df.text = df.text.str.replace(r'(RT|rt)[ ]*@[ ]*[\\S]+',r'')\n",
        "df.text = df.text.str.replace(r'@[\\S]+',r'')\n",
        "\n",
        "# Remove non-ascii words or characters\n",
        "df.text = [''.join([i if ord(i) < 128 else '' for i in text]) for text in df.text]\n",
        "df.text = df.text.str.replace(r'_[\\S]?',r'')\n",
        "\n",
        "# Remove extra space\n",
        "df.text = df.text.str.replace(r'[ ]{2, }',r' ')\n",
        "\n",
        "# Remove &, < and >\n",
        "df.text = df.text.str.replace(r'&amp;?',r'and')\n",
        "df.text = df.text.str.replace(r'&lt;',r'<')\n",
        "df.text = df.text.str.replace(r'&gt;',r'>')\n",
        "\n",
        "# Insert space between words and punctuation marks\n",
        "df.text = df.text.str.replace(r'([\\w\\d]+)([^\\w\\d ]+)', r'\\1 \\2')\n",
        "df.text = df.text.str.replace(r'([^\\w\\d ]+)([\\w\\d]+)', r'\\1 \\2')\n",
        "\n",
        "# Lowercased and strip\n",
        "df.text = df.text.str.lower()\n",
        "df.text = df.text.str.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffQeENlCz-Fn",
        "colab_type": "code",
        "outputId": "fdf30582-eed4-445e-c210-3ab2937b8167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df['text_length'] = [len(text.split(' ')) for text in df.text]\n",
        "print(df.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14640, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeqAhAyHz_sM",
        "colab_type": "code",
        "outputId": "1968c075-6a3b-4dce-b129-d4c2c8e70d6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "\n",
        "# Drop texts with length <=3 and drop duplicates\n",
        "df = df[df['text_length']>3]\n",
        "df = df.drop_duplicates(subset=['text'])\n",
        "\n",
        "print(df.shape)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13977, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMTR8g-w0BNo",
        "colab_type": "code",
        "outputId": "42f11ac5-efbb-4ade-dbe7-9f9142e5d147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Summary of sample size and labels\n",
        "df.shape[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13977"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Weqa07t90C8o",
        "colab_type": "code",
        "outputId": "394a0754-b1e9-4643-a6aa-22ef5a30a17a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "df.airline_sentiment.value_counts()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    8998\n",
              "neutral     2834\n",
              "positive    2145\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj8feOCk0F_8",
        "colab_type": "code",
        "outputId": "ee52dd59-596a-4fdf-e781-04846d2ae0ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "df['BERT_processed_text'] = '[CLS] '+df.text\n",
        "df.BERT_processed_text"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet_id\n",
              "570306133677760513                                   [CLS] what  said .\n",
              "570301130888122368    [CLS] plus you ' ve added commercials to the e...\n",
              "570301083672813571    [CLS] i didn ' t today ... must mean i need to...\n",
              "570301031407624196    [CLS] it ' s really aggressive to blast obnoxi...\n",
              "570300817074462722     [CLS] and it ' s a really big bad thing about it\n",
              "                                            ...                        \n",
              "569587686496825344    [CLS] thank you we got on a different flight t...\n",
              "569587371693355008    [CLS] leaving over 20 minutes late flight . no...\n",
              "569587242672398336    [CLS] please bring american airlines to # blac...\n",
              "569587188687634433    [CLS] you have my money , you change my flight...\n",
              "569587140490866689    [CLS] we have 8 ppl so we need 2 know how many...\n",
              "Name: BERT_processed_text, Length: 13977, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXkRZ8ct0ENA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "df['BERT_processed_text_length'] = [len(tokenizer.tokenize(sent)) for sent in df.text]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPTDpbY_0ItI",
        "colab_type": "code",
        "outputId": "f233cf9c-7760-4978-ca96-04cf25f4a87c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "df.BERT_processed_text_length"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet_id\n",
              "570306133677760513     3\n",
              "570301130888122368    15\n",
              "570301083672813571    17\n",
              "570301031407624196    25\n",
              "570300817074462722    11\n",
              "                      ..\n",
              "569587686496825344    11\n",
              "569587371693355008    27\n",
              "569587242672398336     8\n",
              "569587188687634433    29\n",
              "569587140490866689    34\n",
              "Name: BERT_processed_text_length, Length: 13977, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECKUGAQq0LMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dict = dict()\n",
        "for i, l in enumerate(list(df.airline_sentiment.value_counts().keys())):\n",
        "    label_dict.update({l: i})\n",
        "\n",
        "df['airline_sentiment_label'] = [label_dict[label] for label in df.airline_sentiment]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6lHcgYx0OLs",
        "colab_type": "code",
        "outputId": "b2990461-3dc3-4016-dd07-576eb194e88b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "df.airline_sentiment_label"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet_id\n",
              "570306133677760513    1\n",
              "570301130888122368    2\n",
              "570301083672813571    1\n",
              "570301031407624196    0\n",
              "570300817074462722    0\n",
              "                     ..\n",
              "569587686496825344    2\n",
              "569587371693355008    0\n",
              "569587242672398336    1\n",
              "569587188687634433    0\n",
              "569587140490866689    1\n",
              "Name: airline_sentiment_label, Length: 13977, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw7HqK4c0Pu9",
        "colab_type": "code",
        "outputId": "a425af83-8753-4ca7-bc70-604959cd87ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "# !touch /content/gdrive/My\\ Drive/Colab\\ Notebooks/bert_processed_twitter_airline_sentiment.csv\n",
        "!ls /content/drive/My\\ Drive/Colab\\ Notebooks\n",
        "df.to_csv(pwd + '/My Drive/Colab Notebooks/bert_processed_twitter_airline_sentiment.csv')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ANTON_BERT.ipynb\n",
            " ANTON_EGO.ipynb\n",
            " ANTON_WITH_BERT_AGORA_VAI.ipynb\n",
            " bert_processed_twitter_airline_sentiment.csv\n",
            " BertPyTorch.ipynb\n",
            " BertTensorflow.ipynb\n",
            " BERT_WORD2VEC.ipynb\n",
            "'Copy of BertPyTorch.ipynb'\n",
            " st-sentiment_bert-base-uncased_model.bin\n",
            " st-sentiment_bert-base-uncased_model.bin.optim\n",
            " TensorflowBasics.ipynb\n",
            " teste.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_a9vdum0TmK",
        "colab_type": "code",
        "outputId": "8947cb9a-769b-49e0-899d-abe722af75cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "!ls /content/drive/My\\ Drive/Colab\\ Notebooks"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ANTON_BERT.ipynb\n",
            " ANTON_EGO.ipynb\n",
            " ANTON_WITH_BERT_AGORA_VAI.ipynb\n",
            " bert_processed_twitter_airline_sentiment.csv\n",
            " BertPyTorch.ipynb\n",
            " BertTensorflow.ipynb\n",
            " BERT_WORD2VEC.ipynb\n",
            "'Copy of BertPyTorch.ipynb'\n",
            " st-sentiment_bert-base-uncased_model.bin\n",
            " st-sentiment_bert-base-uncased_model.bin.optim\n",
            " TensorflowBasics.ipynb\n",
            " teste.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kvtMmWu0aEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GPd3H1c0d65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define training params\n",
        "label_names = ['positive', 'negative', 'neutral']\n",
        "model_name = 'st-sentiment'\n",
        "device = torch.device(\"cuda:0\")\n",
        "bert_size = 'bert-base-uncased'\n",
        "\n",
        "train_batch_size = 32 # batch size\n",
        "clip_grad = 1.0 # gradient clipping\n",
        "log_every = 10 # number of mini-batches before logging\n",
        "max_epoch = 100 # max number of epochs\n",
        "max_patience = 3 # number of iterations to wait before decaying learning rate\n",
        "max_num_trial = 3 # number of trials before terminating training\n",
        "lr_decay = 0.5 # learning rate decay\n",
        "lr_bert = 0.00002 # BERT learning rate\n",
        "lr = 0.001 # learning rate\n",
        "valid_niter = 500 # perform validation after n iterations\n",
        "dropout = 0.3 # dropout rate\n",
        "verbose = True\n",
        "\n",
        "prefix = model_name + '_' + bert_size\n",
        "model_save_path = pwd + '/My Drive/Colab Notebooks/' + prefix+'_model.bin'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsimG9Tb0nuw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c6ce2245-2936-44aa-80e8-a95c075da7fc"
      },
      "source": [
        "training_data,validation_data = train_test_split(df,test_size=0.2,random_state=42)\n",
        "print(len(df), len(training_data), len(validation_data))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13977 11181 2796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLH2TCr50rUc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "127352e4-3ec9-4f97-de1d-68a9c5d311c7"
      },
      "source": [
        "print(training_data)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   airline_sentiment  ... airline_sentiment_label\n",
            "tweet_id                              ...                        \n",
            "569593278636675072          negative  ...                       0\n",
            "568621033273602048          positive  ...                       2\n",
            "569786809028255744          negative  ...                       0\n",
            "569673900805783552          negative  ...                       0\n",
            "568809510644527104          negative  ...                       0\n",
            "...                              ...  ...                     ...\n",
            "569162467051474944          negative  ...                       0\n",
            "569671368788172800          negative  ...                       0\n",
            "568885499986874369           neutral  ...                       1\n",
            "570027321178099712           neutral  ...                       1\n",
            "569530159247826944          positive  ...                       2\n",
            "\n",
            "[11181 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8bx1mfU0s3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c5710666-4f02-4f01-a84b-98a430c7bf5a"
      },
      "source": [
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "\n",
        "train_label = dict(training_data.airline_sentiment_label.value_counts())\n",
        "label_max = float(max(train_label.values()))\n",
        "train_label_weight = torch.tensor([label_max/train_label[i] for i in range(len(train_label))], device=device)\n",
        "\n",
        "pp.pprint(train_label_weight)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0000, 3.2735, 4.2780], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVC9fXT20uEK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e0eaba74-bf59-4f98-d047-c1e075799127"
      },
      "source": [
        "# Set up model and optimizer\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "model = SentimentClassifierModel(bert_size, device, len(label_names))\n",
        "optimizer = AdamW([\n",
        "        {'params': model.bert.bert.parameters()},\n",
        "        {'params': model.bert.classifier.parameters(), 'lr': float(lr)}\n",
        "    ], lr=float(lr_bert))\n",
        "\n",
        "model = model.to(device)\n",
        "print('Use device: %s' % device, file=sys.stderr)\n",
        "print('Done! time elapsed %.2f sec' % (time.time() - start_time), file=sys.stderr)\n",
        "print('-' * 80, file=sys.stderr)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use device: cuda:0\n",
            "Done! time elapsed 3.26 sec\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQCa-uNC0wEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Util functions for training\n",
        "import math\n",
        "import logging\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import sys\n",
        "from docopt import docopt\n",
        "from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix, \\\n",
        "    f1_score, precision_score, recall_score, roc_auc_score\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def batch_iter(data, batch_size, shuffle=False, bert=None):\n",
        "    \"\"\" Yield batches of sentences and labels reverse sorted by length (largest to smallest).\n",
        "    @param data (dataframe): dataframe with ProcessedText (str) and label (int) columns\n",
        "    @param batch_size (int): batch size\n",
        "    @param shuffle (boolean): whether to randomly shuffle the dataset\n",
        "    @param bert (str): whether for BERT training. Values: \"large\", \"base\", None\n",
        "    \"\"\"\n",
        "    batch_num = math.ceil(data.shape[0] / batch_size)\n",
        "    index_array = list(range(data.shape[0]))\n",
        "\n",
        "    if shuffle:\n",
        "        data = data.sample(frac=1)\n",
        "\n",
        "    for i in range(batch_num):\n",
        "        indices = index_array[i * batch_size: (i + 1) * batch_size]\n",
        "        examples = data.iloc[indices].sort_values(by='BERT_processed_text_length', ascending=False)\n",
        "        sents = list(examples.BERT_processed_text)\n",
        "\n",
        "        targets = list(examples.airline_sentiment_label.values)\n",
        "        yield sents, targets  # list[list[str]] if not bert else list[str], list[int]\n",
        "        \n",
        "def validation(model, df_val, bert_size, loss_func, device):\n",
        "    \"\"\" validation of model during training.\n",
        "    @param model (nn.Module): the model being trained\n",
        "    @param df_val (dataframe): validation dataset\n",
        "    @param bert_size (str): large or base\n",
        "    @param loss_func(nn.Module): loss function\n",
        "    @param device (torch.device)\n",
        "    @return avg loss value across validation dataset\n",
        "    \"\"\"\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "\n",
        "    df_val = df_val.sort_values(by='BERT_processed_text_length', ascending=False)\n",
        "\n",
        "    ProcessedText_BERT = list(df_val.BERT_processed_text)\n",
        "    InformationType_label = list(df_val.airline_sentiment_label)\n",
        "\n",
        "    val_batch_size = 32\n",
        "\n",
        "    n_batch = int(np.ceil(df_val.shape[0]/val_batch_size))\n",
        "\n",
        "    total_loss = 0.\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(n_batch):\n",
        "            sents = ProcessedText_BERT[i*val_batch_size: (i+1)*val_batch_size]\n",
        "            targets = torch.tensor(InformationType_label[i*val_batch_size: (i+1)*val_batch_size],\n",
        "                                   dtype=torch.long, device=device)\n",
        "            batch_size = len(sents)\n",
        "            pre_softmax = model(sents)[0]\n",
        "            batch_loss = loss_func(pre_softmax, targets)\n",
        "            total_loss += batch_loss.item()*batch_size\n",
        "\n",
        "    if was_training:\n",
        "        model.train()\n",
        "\n",
        "    return total_loss/df_val.shape[0]\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None, path='cm', cmap=plt.cm.Reds):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    pickle.dump(cm, open(path, 'wb'))\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T7qNutI0zUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Train\n",
        "\n",
        "model.train()\n",
        "cn_loss = torch.nn.CrossEntropyLoss(weight=train_label_weight, reduction='mean')\n",
        "torch.save(cn_loss, 'loss_func')  # for later testing\n",
        "\n",
        "# Initialize training variables\n",
        "num_trial = 0\n",
        "train_iter = 0\n",
        "patience = 0\n",
        "cum_loss = 0\n",
        "report_loss = 0\n",
        "cum_examples = report_examples = epoch = 0\n",
        "hist_valid_scores = []\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck8Livq-01Qo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ecc9252-659f-4cb3-f09a-d070cd8dcd92"
      },
      "source": [
        "! ls"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  loss_func  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEYMrunH06dY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fa8ed846-4b33-4490-ef71-75f08dbca812"
      },
      "source": [
        "import time\n",
        "\n",
        "train_time = begin_time = time.time()\n",
        "print('Begin Maximum Likelihood training...')\n",
        "\n",
        "# Training loop\n",
        "while True:\n",
        "    epoch += 1\n",
        "    for sents, targets in batch_iter(training_data, batch_size=train_batch_size, shuffle=True, bert='base'):  # for each epoch\n",
        "        train_iter += 1\n",
        "        optimizer.zero_grad()\n",
        "        batch_size = len(sents)\n",
        "        pre_softmax = model(sents)[0]\n",
        "\n",
        "        # Calculate loss and gradient function\n",
        "        loss = cn_loss(pre_softmax, torch.tensor(targets, dtype=torch.long, device=device))\n",
        "        loss.backward()\n",
        "\n",
        "        # Next step\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_losses_val = loss.item() * batch_size\n",
        "        report_loss += batch_losses_val\n",
        "        cum_loss += batch_losses_val\n",
        "\n",
        "        report_examples += batch_size\n",
        "        cum_examples += batch_size\n",
        "\n",
        "        if train_iter % log_every == 0:\n",
        "            print('epoch %d, iter %d, avg. loss %.2f, '\n",
        "                  'cum. examples %d, speed %.2f examples/sec, '\n",
        "                  'time elapsed %.2f sec' % (epoch, train_iter,\n",
        "                     report_loss / report_examples,\n",
        "                     cum_examples,\n",
        "                     report_examples / (time.time() - train_time),\n",
        "                     time.time() - begin_time), file=sys.stderr)\n",
        "\n",
        "            train_time = time.time()\n",
        "            report_loss = report_examples = 0.\n",
        "\n",
        "        # perform validation\n",
        "        if train_iter % valid_niter == 0:\n",
        "            print('epoch %d, iter %d, cum. loss %.2f, cum. examples %d' % (epoch, train_iter,\n",
        "                 cum_loss / cum_examples,\n",
        "                 cum_examples), file=sys.stderr)\n",
        "\n",
        "            cum_loss = cum_examples = 0.\n",
        "\n",
        "            print('begin validation ...', file=sys.stderr)\n",
        "\n",
        "            validation_loss = validation(model, validation_data, bert_size, cn_loss, device)   # dev batch size can be a bit larger\n",
        "\n",
        "            print('validation: iter %d, loss %f' % (train_iter, validation_loss), file=sys.stderr)\n",
        "\n",
        "            is_better = len(hist_valid_scores) == 0 or validation_loss < min(hist_valid_scores)\n",
        "            hist_valid_scores.append(validation_loss)\n",
        "\n",
        "            if is_better:\n",
        "                patience = 0\n",
        "                print('save currently the best model to [%s]' % model_save_path, file=sys.stderr)\n",
        "\n",
        "                model.save(model_save_path)\n",
        "\n",
        "                # also save the optimizers' state\n",
        "                torch.save(optimizer.state_dict(), model_save_path + '.optim')\n",
        "            elif patience < int(max_patience):\n",
        "                patience += 1\n",
        "                print('hit patience %d' % patience, file=sys.stderr)\n",
        "\n",
        "                if patience == int(max_patience):\n",
        "                    num_trial += 1\n",
        "                    print('hit #%d trial' % num_trial, file=sys.stderr)\n",
        "                    if num_trial == max_num_trial:\n",
        "                        print('early stop!', file=sys.stderr)\n",
        "                        exit(0)\n",
        "\n",
        "                    # decay lr, and restore from previously best checkpoint\n",
        "                    print('load previously best model and decay learning rate to %f%%' %\n",
        "                          (float(lr_decay)*100), file=sys.stderr)\n",
        "\n",
        "                    # load model\n",
        "                    params = torch.load(model_save_path, map_location=lambda storage, loc: storage)\n",
        "                    model.load_state_dict(params['state_dict'])\n",
        "                    model = model.to(device)\n",
        "\n",
        "                    print('restore parameters of the optimizers', file=sys.stderr)\n",
        "                    optimizer.load_state_dict(torch.load(model_save_path + '.optim'))\n",
        "\n",
        "                    # set new lr\n",
        "                    for param_group in optimizer.param_groups:\n",
        "                        param_group['lr'] *= float(lr_decay)\n",
        "\n",
        "                    # reset patience\n",
        "                    patience = 0\n",
        "\n",
        "            if epoch == int(max_epoch):\n",
        "                print('reached maximum number of epochs!', file=sys.stderr)\n",
        "                exit(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 139, iter 48540, avg. loss 0.09, cum. examples 1280, speed 213.92 examples/sec, time elapsed 7623.30 sec\n",
            "epoch 139, iter 48550, avg. loss 0.08, cum. examples 1600, speed 216.04 examples/sec, time elapsed 7624.79 sec\n",
            "epoch 139, iter 48560, avg. loss 0.14, cum. examples 1920, speed 211.66 examples/sec, time elapsed 7626.30 sec\n",
            "epoch 139, iter 48570, avg. loss 0.13, cum. examples 2240, speed 219.14 examples/sec, time elapsed 7627.76 sec\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-29-40a22b790974>\", line 17, in <module>\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 195, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 99, in backward\n",
            "    allow_unreachable=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 396, in realpath\n",
            "    return abspath(path)\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 385, in abspath\n",
            "    return normpath(path)\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 359, in normpath\n",
            "    comps = path.split(sep)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n",
            "    callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
            "    return self.dispatch_shell(stream, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
            "    handler(stream, idents, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 421, in execute_request\n",
            "    self._abort_queues()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 636, in _abort_queues\n",
            "    self._abort_queue(stream)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 657, in _abort_queue\n",
            "    self._publish_status('idle', parent=msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 327, in _publish_status\n",
            "    ident=self._topic('status'),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\", line 737, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\", line 636, in serialize\n",
            "    self.pack(msg['parent_header']),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\", line 103, in <lambda>\n",
            "    ensure_ascii=False, allow_nan=False,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/utils/jsonapi.py\", line 40, in dumps\n",
            "    s = jsonmod.dumps(o, **kwargs)\n",
            "  File \"/usr/lib/python3.6/json/__init__.py\", line 238, in dumps\n",
            "    **kw).encode(obj)\n",
            "  File \"/usr/lib/python3.6/json/encoder.py\", line 199, in encode\n",
            "    chunks = self.iterencode(o, _one_shot=True)\n",
            "  File \"/usr/lib/python3.6/json/encoder.py\", line 250, in iterencode\n",
            "    self.key_separator, self.item_separator, self.sort_keys,\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm3FbqJB07I-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#validation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT-8rgGs6mKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix, \\\n",
        "f1_score, precision_score, recall_score, roc_auc_score\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyQCzrVj6m7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None, path='cm', cmap=plt.cm.Reds):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    pickle.dump(cm, open(path, 'wb'))\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7pK6j1D6o10",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "7189a6d3-e0a4-432a-a9a3-359a4c728651"
      },
      "source": [
        "print('load best model...')\n",
        "\n",
        "model = SentimentClassifierModel.load('/content/drive/My Drive/Colab Notebooks/' + prefix + '_model.bin', device)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "df_test = validation_data\n",
        "\n",
        "df_test = df_test.sort_values(by='BERT_processed_text_length', ascending=False)\n",
        "\n",
        "test_batch_size = 32\n",
        "\n",
        "n_batch = int(np.ceil(df_test.shape[0]/test_batch_size))\n",
        "\n",
        "cn_loss = torch.load('loss_func', map_location=lambda storage, loc: storage).to(device)\n",
        "\n",
        "ProcessedText_BERT = list(df_test.BERT_processed_text)\n",
        "InformationType_label = list(df_test.airline_sentiment_label)\n",
        "\n",
        "test_loss = 0.\n",
        "prediction = []\n",
        "prob = []\n",
        "\n",
        "softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(n_batch):\n",
        "        sents = ProcessedText_BERT[i*test_batch_size: (i+1)*test_batch_size]\n",
        "        targets = torch.tensor(InformationType_label[i * test_batch_size: (i + 1) * test_batch_size],\n",
        "                                   dtype=torch.long, device=device)\n",
        "        batch_size = len(sents)\n",
        "\n",
        "        pre_softmax = model(sents)[0]\n",
        "        batch_loss = cn_loss(pre_softmax, targets)\n",
        "        test_loss += batch_loss.item()*batch_size\n",
        "        prob_batch = softmax(pre_softmax)\n",
        "        prob.append(prob_batch)\n",
        "\n",
        "        prediction.extend([t.item() for t in list(torch.argmax(prob_batch, dim=1))])\n",
        "\n",
        "prob = torch.cat(tuple(prob), dim=0)\n",
        "loss = test_loss/df_test.shape[0]\n",
        "\n",
        "pickle.dump([label_names[i] for i in prediction], open(prefix+'_test_prediction', 'wb'))\n",
        "pickle.dump(prob.data.cpu().numpy(), open(prefix + '_test_prediction_prob', 'wb'))\n",
        "\n",
        "accuracy = accuracy_score(df_test.airline_sentiment_label.values, prediction)\n",
        "matthews = matthews_corrcoef(df_test.airline_sentiment_label.values, prediction)\n",
        "\n",
        "precisions = {}\n",
        "recalls = {}\n",
        "f1s = {}\n",
        "aucrocs = {}\n",
        "\n",
        "for i in range(len(label_names)):\n",
        "    prediction_ = [1 if pred == i else 0 for pred in prediction]\n",
        "    true_ = [1 if label == i else 0 for label in df_test.airline_sentiment_label.values]\n",
        "    f1s.update({label_names[i]: f1_score(true_, prediction_)})\n",
        "    precisions.update({label_names[i]: precision_score(true_, prediction_)})\n",
        "    recalls.update({label_names[i]: recall_score(true_, prediction_)})\n",
        "    aucrocs.update({label_names[i]: roc_auc_score(true_, list(t.item() for t in prob[:, i]))})\n",
        "\n",
        "metrics_dict = {'loss': loss, 'accuracy': accuracy, 'matthews coef': matthews, 'precision': precisions,\n",
        "                         'recall': recalls, 'f1': f1s, 'aucroc': aucrocs}\n",
        "\n",
        "pickle.dump(metrics_dict, open(prefix+'_evaluation_metrics', 'wb'))\n",
        "\n",
        "cm = plot_confusion_matrix(list(df_test.airline_sentiment_label.values), prediction, label_names, normalize=False,\n",
        "                          path=prefix+'_test_confusion_matrix', title='confusion matrix for test dataset')\n",
        "plt.savefig(prefix+'_test_confusion_matrix', format='png')\n",
        "cm_norm = plot_confusion_matrix(list(df_test.airline_sentiment_label.values), prediction, label_names, normalize=True,\n",
        "                          path=prefix+'_test normalized_confusion_matrix', title='normalized confusion matrix for test dataset')\n",
        "plt.savefig(prefix+'_test_normalized_confusion_matrix', format='png')\n",
        "\n",
        "print('loss: %.2f' % loss)\n",
        "print('accuracy: %.2f' % accuracy)\n",
        "print('matthews coef: %.2f' % matthews)\n",
        "print('-' * 80)\n",
        "for i in range(len(label_names)):\n",
        "    print('precision score for %s: %.2f' % (label_names[i], precisions[label_names[i]]))\n",
        "    print('recall score for %s: %.2f' % (label_names[i], recalls[label_names[i]]))\n",
        "    print('f1 score for %s: %.2f' % (label_names[i], f1s[label_names[i]]))\n",
        "    print('auc roc score for %s: %.2f' % (label_names[i], aucrocs[label_names[i]]))\n",
        "    print('-' * 80)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "load best model...\n",
            "loss: 0.51\n",
            "accuracy: 0.82\n",
            "matthews coef: 0.68\n",
            "--------------------------------------------------------------------------------\n",
            "precision score for positive: 0.93\n",
            "recall score for positive: 0.83\n",
            "f1 score for positive: 0.88\n",
            "auc roc score for positive: 0.94\n",
            "--------------------------------------------------------------------------------\n",
            "precision score for negative: 0.62\n",
            "recall score for negative: 0.77\n",
            "f1 score for negative: 0.69\n",
            "auc roc score for negative: 0.90\n",
            "--------------------------------------------------------------------------------\n",
            "precision score for neutral: 0.76\n",
            "recall score for neutral: 0.82\n",
            "f1 score for neutral: 0.79\n",
            "auc roc score for neutral: 0.96\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDw8XXQ06sQQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f90cf04b-9346-439e-bf2d-ed2f02d5f3c3"
      },
      "source": [
        "precisions"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'negative': 0.6245059288537549,\n",
              " 'neutral': 0.756198347107438,\n",
              " 'positive': 0.9311010946555055}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN5ODuzW6yXC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f8ab1c12-f1aa-498d-a75b-8d321023a9d6"
      },
      "source": [
        "\n",
        "\n",
        "recalls\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'negative': 0.7707317073170732,\n",
              " 'neutral': 0.8187919463087249,\n",
              " 'positive': 0.8339100346020761}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H6wCBOn6zl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8526ac00-58ed-45b6-c618-c05578f6ee77"
      },
      "source": [
        "f1s"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'negative': 0.6899563318777292,\n",
              " 'neutral': 0.78625134264232,\n",
              " 'positive': 0.8798296318831762}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7us66EK60mV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "63a80a02-dbe2-49d2-9b4e-baa61d5c540e"
      },
      "source": [
        "aucrocs"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'negative': 0.9044422823870604,\n",
              " 'neutral': 0.9643572446935865,\n",
              " 'positive': 0.9388083027605635}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnfySVWH62VR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "e54c77bc-e3c6-48fe-df40-58fb58d78859"
      },
      "source": [
        "import pandas\n",
        "st_df = pandas.read_csv(\"/content/drive/My Drive/Colab Notebooks/st-comments.csv\", index_col=0, encoding='latin-1', usecols=['comment_id','post_title', 'comment_text'])\n",
        "st_df.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e5e5b67507b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mst_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Colab Notebooks/st-comments.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'post_title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'comment_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mst_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1874\u001b[0;31m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1875\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/st-comments.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yulFztJ764Gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove URL, RT, mention(@)\n",
        "\n",
        "st_df['text'] = st_df.comment_text\n",
        "\n",
        "st_df.text = st_df.text.str.replace(r'http(\\S)+', r'')\n",
        "st_df.text = st_df.text.str.replace(r'http ...', r'')\n",
        "st_df.text = st_df.text.str.replace(r'(RT|rt)[ ]*@[ ]*[\\S]+',r'')\n",
        "st_df.text = st_df.text.str.replace(r'@[\\S]+',r'')\n",
        "\n",
        "# Remove non-ascii words or characters\n",
        "st_df.text = [''.join([i if ord(i) < 128 else '' for i in text]) for text in st_df.text]\n",
        "st_df.text = st_df.text.str.replace(r'_[\\S]?',r'')\n",
        "\n",
        "# Remove extra space\n",
        "st_df.text = st_df.text.str.replace(r'[ ]{2, }',r' ')\n",
        "\n",
        "# Remove &, < and >\n",
        "st_df.text = st_df.text.str.replace(r'&amp;?',r'and')\n",
        "st_df.text = st_df.text.str.replace(r'&lt;',r'<')\n",
        "st_df.text = st_df.text.str.replace(r'&gt;',r'>')\n",
        "\n",
        "# Insert space between words and punctuation marks\n",
        "st_df.text = st_df.text.str.replace(r'([\\w\\d]+)([^\\w\\d ]+)', r'\\1 \\2')\n",
        "st_df.text = st_df.text.str.replace(r'([^\\w\\d ]+)([\\w\\d]+)', r'\\1 \\2')\n",
        "\n",
        "# Lowercased and strip\n",
        "st_df.text = st_df.text.str.lower()\n",
        "st_df.text = st_df.text.str.strip()\n",
        "\n",
        "st_df['text_length'] = [len(text.split(' ')) for text in st_df.text]\n",
        "print(st_df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLAaxAhO67q-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st_df['BERT_processed_text'] = '[CLS] '+ st_df.text\n",
        "st_df.BERT_processed_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fib9K1n6-Fx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "st_df['BERT_processed_text_length'] = [len(tokenizer.tokenize(sent)) for sent in st_df.text]\n",
        "st_df.BERT_processed_text_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2NAPkqS6_LA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0BBrQJi7Buj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st_df.to_csv(pwd + '/My Drive/Colab Notebooks/bert_processed_st_comments.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tXH0K1x7DIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load model\n",
        "model = SentimentClassifierModel.load('/content/drive/My Drive/Colab Notebooks/' + prefix + '_model.bin', device)\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FavXnTFz7G4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st_df = st_df.sort_values(by='BERT_processed_text_length', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xzQKEE37IAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_IA3OsH7KBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cn_loss = torch.load('loss_func', map_location=lambda storage, loc: storage).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVRCemn17LQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ProcessedText_BERT = list(st_df.BERT_processed_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5XGUGzr7M2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ProcessedText_BERT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zt9GAAi7PiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "softmax = torch.nn.Softmax(dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKcN7QUx7QyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = ['negative', 'neutral', 'positive']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o10-HCG07Rbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents = ProcessedText_BERT[:2]\n",
        "sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9nhwnBF7SjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(sents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_Q_Bvb57T_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "pre_softmax = model(sents)[0]\n",
        "pre_softmax\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5iF5b1j7VKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_softmax.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o8I-q6X7XuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prob = softmax(pre_softmax)\n",
        "prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmIzZHBs7Zy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "prob.shape\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dj1JsWr7aoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prob[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDynhhQk7dFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_indexes = [t.item() for t in list(torch.argmax(prob, dim=1))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYzQPfdp7ehx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = labels[label_indexes[1]]\n",
        "prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPdpuuN37hQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = []\n",
        "with torch.no_grad():\n",
        "  sents = ProcessedText_BERT\n",
        "  pre_softmax = model(sents)[0]\n",
        "  prob = softmax(pre_softmax)\n",
        "  predictions.extend([t.item() for t in list(torch.argmax(prob, dim=1))])\n",
        "print(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VokxHzar7iUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[labels[pred_val] for pred_val in predictions]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgVrvTvy7ku7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st_df['predictions'] = [labels[pred_val] for pred_val in predictions]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry0jUJEL7mEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(st_df.comment_text[90])\n",
        "print(st_df.predictions[90])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7wvdUFP7nKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st_df.to_csv(pwd + '/My Drive/Colab Notebooks/bert_predicted_st_comments.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxQDCWML7oxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st_df.predictions.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}